{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379c335b",
   "metadata": {},
   "source": [
    "# Midterm Exam\n",
    "\n",
    "- **Subject:** Computational Physics I\n",
    "- **Date:** Tuesday 27 June 2023\n",
    "- **Credits:** 30 points\n",
    "- **Number of problems:** 6\n",
    "- **Type of evaluation:** Midterm Exam\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "- When you finish, please send your .ipynb file via email to wbanda@yachaytech.edu.ec\n",
    "\n",
    "\n",
    "- The exam is open-book and has two parts:\n",
    "\n",
    "**Part 1** should be submitted **individually** by the end of the class today.\n",
    "\n",
    "        \n",
    "**Part 2** can be submitted **individually or in pairs** by Friday 7th July (by the end of the day).\n",
    "\n",
    "\n",
    "- You can call your notebook with your surname/s, e.g. name.ipynb, and also include your name/s in the notebook.\n",
    "\n",
    "\n",
    "- Within a **single python notebook**, add the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e921bad",
   "metadata": {},
   "source": [
    "## Part II (18 points): due by Monday 10 July (by the end of the day)\n",
    "\n",
    "### 4. (6 points) Period of the tide using sea level data\n",
    "\n",
    "The goal of this exercise is to calculate the period of the sea level change with the tide. For this, we are going to use sea level measurements from the data base of the University of Hawaii: \n",
    "\n",
    "http://uhslc.soest.hawaii.edu/data/?fd\n",
    "\n",
    "These data sets were collected from more than $500$ tide gauge stations across the globe.\n",
    "\n",
    "(a) Go to the website of the sea level data base and search for measurements from Ecuador. Download the \"Research Quality\" \"hourly\" data for Santa Cruz. These data sets are **csv** files with 5 columns each (year, month, day, hour, sea level). The units of the sea level data are $\\rm mm$.\n",
    "\n",
    "(b) Using pandas, read in the data from the data files and check the data by ploting the sea level measurement against the hours.\n",
    "\n",
    "(c) Remove extreme outliers from the data. Outliers show up as negative values that occur when instruments fail.\n",
    "\n",
    "(d) Calculate the average sea level at each hour for Santa Cruz and make a plot (average sea level against hours). What trend do you notice in the data?\n",
    "\n",
    "(e) Fit an appropriate function to the data to model the hourly change of the sea level also known as the tide (if you use curvefit(), I suggest providing ansatz values).\n",
    "\n",
    "(f) Based on the fitted function, what period does the tide have? \n",
    "\n",
    "**Reference:**\n",
    "Caldwell, P. C., M. A. Merrifield, P. R. Thompson (2015), Sea level measured by tide gauges from global oceans â€” the Joint Archive for Sea Level holdings (NCEI Accession 0019568), Version 5.5, NOAA National Centers for Environmental Information, Dataset, doi:10.7289/V5V40S7W."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd50239",
   "metadata": {},
   "source": [
    "### 5. (6 points) Distance between colliding galaxies\n",
    "\n",
    "The purpose of this exercise in to isolate features (galaxies) in an image by analysing the pixel information.\n",
    "\n",
    "The sample data correspond to NGC 5765, which is a system of two merging spiral galaxies (see https://en.wikipedia.org/wiki/NGC_5765). The galaxies are in the early stages of the merger, where the interaction between them is clear, through extended arms caused by the tidal interaction, but the galaxies are still clearly separated. \n",
    "\n",
    "The provided data file:\n",
    "\n",
    "https://github.com/wbandabarragan/computational-physics-1/tree/main/exams/data_sets/NGC_5765_legacy_survey.fits\n",
    "\n",
    "contains optical images of the two galaxies from the DESI Legacy Imaging Survey (https://www.legacysurvey.org/). The FITS file contains 3 images which were taken with the g, r, z filters, which show optical light at slightly different wavelengths.\n",
    "\n",
    "Carry out the following analysis:\n",
    "\n",
    "(a) Read in the data from the FITS file and select the first channel of the image.\n",
    "\n",
    "(b) Mask the image, leaving only the region containing only the merging galaxies.\n",
    "\n",
    "(c) Identify the centre of each galaxy. These are the two brightest regions in the image.\n",
    "\n",
    "(d) Calculate the distance (in pixels) between the centres of the two galaxies.\n",
    "\n",
    "(e) To convert the pixel units into degrees use the information from the header (key: \"CD_1\", which reports the size of a pixel in degrees). To convert to distance units (Mpc) use trigonometry and the knowledge that these galaxies are at a distance of $126\\,\\rm Mpc$ from us.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bbf73a",
   "metadata": {},
   "source": [
    "### 6. (6 points) Turbulence in 2D\n",
    "\n",
    "We want to study the properties of the velocity field of turbulent flows in 2D. Let us consider a high-resolution version of the turbulence-in-a-box simulation we analysed in class:\n",
    "\n",
    "https://github.com/wbandabarragan/computational-physics-1/tree/main/exams/data_sets/TURB_DRIVE_SUP_hr.zip\n",
    "\n",
    "This simulation introduces a stochastic force field to generate turbulent motions in an isothermal ($\\gamma=1$) gas initially at rest. Turbulence is continuously generated throughout the whole simulation time.\n",
    "\n",
    "The simulation folder contains 101 VTK files, jointly with:\n",
    "\n",
    "- a **units.out** file that contains the CGS normalisation values.\n",
    "- a **vtk.out** file whose second column contains the times in code units.\n",
    "\n",
    "Each VTK file stores the following fields:\n",
    "\n",
    "- density (rho)\n",
    "- velocity_x (vx1)\n",
    "- velocity_y (vx2)\n",
    "- magnetic_field_x (Bx1)\n",
    "- magnetic_field_y (Bx2)\n",
    "\n",
    "We will only use the velocity field for this exercise.\n",
    "\n",
    "\n",
    "(a) Write a python function that reads and returns the components of the velocity field normalised in CGS units, for any VTK file.\n",
    "\n",
    "(b) Call the above function for VTK file # 50, calculate the modulus of the velocity field, and make two separate maps: one of the modulus of the velocity field and one of the vector field itself.\n",
    "\n",
    "(c) Make a 1D histogram of the modulus of the velocity field for VTK file # 50. What kind of distribution does it have? Does the disribution follow any of the cases studied in problem 3?\n",
    "\n",
    "(d) Create a set of Python functions that loops over all the simulation VTK files, and computes the following quantities for each time:\n",
    "\n",
    "- the average velocity, $[v]$,\n",
    "\n",
    "- the rms velocity, $\\sqrt{[v^2]}$,\n",
    "\n",
    "- the (volume-weighted) average velocity dispersion, $\\sigma_v = \\sqrt{[ v^2 ] - [v ]^2}$.\n",
    "\n",
    "- the rms Mach number, for which you need $c_{iso}$ given in units.out,\n",
    "\n",
    "and returns:\n",
    "\n",
    "- a CSV file with 5 columns, time on the first column, and the above quantities in the next ones.\n",
    "\n",
    "- figures of each of the above quantities versus time.\n",
    "\n",
    "\n",
    "(e) Create a Python function that return movies showing the time evolution of:\n",
    "\n",
    "- maps of the modulus of the velocity field, jointly with\n",
    "\n",
    "- the rms Mach numbers computed in (d).\n",
    "\n",
    "Does the flow reach steady state?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
